{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "259f5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fe205d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data from CSV files\n",
    "train = pd.read_csv(\"Dataset/train.csv\")\n",
    "test = pd.read_csv(\"Dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85085baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "# Drop subject/date and concatenating text and title\n",
    "train[\"text\"] = train[\"title\"] + \" \" + train[\"text\"]\n",
    "test[\"text\"] = test[\"title\"] + \" \" + test[\"text\"]\n",
    "\n",
    "train = train.drop([\"subject\", \"date\", \"title\"], axis = 1)\n",
    "test = test.drop([\"subject\", \"date\", \"title\"], axis = 1)\n",
    "\n",
    "def clean_text_data(data_point):\n",
    "    review_soup = BeautifulSoup(data_point)\n",
    "    review_text = review_soup.get_text()\n",
    "    review_letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    review_lower_case = review_letters_only.lower()  \n",
    "    review_words = review_lower_case.split() \n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    meaningful_words = [x for x in review_words if x not in stop_words]\n",
    "        \n",
    "    return(\" \".join(meaningful_words)) \n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(clean_text_data)\n",
    "test[\"text\"] = test[\"text\"].apply(clean_text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "98227ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clinton faces pressure pick vp tough trade wal...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ryan trump cite positive step toward republica...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>watch president obama dares republicans suppor...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hariri warns lebanon faces arab sanctions risk...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poem twas night cnn christmas acr boiler room ...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39893</th>\n",
       "      <td>lol photo accompanying google search pathologi...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39894</th>\n",
       "      <td>trump wants children would break law donald tr...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39895</th>\n",
       "      <td>gay activists march serb capital behind police...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39896</th>\n",
       "      <td>boiler room smoking gunz tune alternate curren...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39897</th>\n",
       "      <td>fire fury trump team talks north korea congres...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39898 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label\n",
       "0      clinton faces pressure pick vp tough trade wal...  real\n",
       "1      ryan trump cite positive step toward republica...  real\n",
       "2      watch president obama dares republicans suppor...  fake\n",
       "3      hariri warns lebanon faces arab sanctions risk...  real\n",
       "4      poem twas night cnn christmas acr boiler room ...  fake\n",
       "...                                                  ...   ...\n",
       "39893  lol photo accompanying google search pathologi...  fake\n",
       "39894  trump wants children would break law donald tr...  fake\n",
       "39895  gay activists march serb capital behind police...  real\n",
       "39896  boiler room smoking gunz tune alternate curren...  fake\n",
       "39897  fire fury trump team talks north korea congres...  real\n",
       "\n",
       "[39898 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View cleaned train dataset\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2815bef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>factbox taxes budget u congress calendar tight...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breaking israel worst fears confirmed says isr...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u drug enforcement chief step agency reuters u...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>factbox trump twitter oct rex tillerson puerto...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fcc chief plans ditch u net neutrality rules w...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>republicans told stop talking healthcare repea...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>texas bill restricting insurance coverage abor...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>montana dems hilariously troll reporter slammi...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>trump says gave classified info russia humanit...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>trump jr paid k event hosted russian allies oc...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label\n",
       "0     factbox taxes budget u congress calendar tight...  real\n",
       "1     breaking israel worst fears confirmed says isr...  fake\n",
       "2     u drug enforcement chief step agency reuters u...  real\n",
       "3     factbox trump twitter oct rex tillerson puerto...  real\n",
       "4     fcc chief plans ditch u net neutrality rules w...  real\n",
       "...                                                 ...   ...\n",
       "4995  republicans told stop talking healthcare repea...  fake\n",
       "4996  texas bill restricting insurance coverage abor...  real\n",
       "4997  montana dems hilariously troll reporter slammi...  fake\n",
       "4998  trump says gave classified info russia humanit...  fake\n",
       "4999  trump jr paid k event hosted russian allies oc...  fake\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View cleaned test dataset\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de5d6f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into Pandas Series for X and Y\n",
    "X_train = pd.DataFrame(train, columns = ['text']).squeeze()\n",
    "X_test = pd.DataFrame(test, columns = ['text']).squeeze()\n",
    "Y_train = pd.DataFrame(train, columns = ['label']).squeeze()\n",
    "Y_test = pd.DataFrame(test, columns = ['label']).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35a0571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text into bag-of-words features\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "14bb4d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    # Constructor, initialize max depth\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    # Fit tree, calls _build tree helper function\n",
    "    def fit(self, X, Y):\n",
    "        self.tree = self._build_tree(X, Y)\n",
    "    \n",
    "    # Make predictions on input data using the trained decision tree model\n",
    "    def predict(self, X):\n",
    "        # Check if X is csr_matrix\n",
    "        if(isinstance(X, scipy.sparse._csr.csr_matrix)):\n",
    "            predictions = []\n",
    "            num_rows, _ = X.shape\n",
    "            for idx in range(num_rows):\n",
    "                prediction = self._traverse_tree(X.getrow(idx).toarray()[0], self.tree)\n",
    "                predictions.append(prediction)\n",
    "        else:\n",
    "            # Slight modification for testing purposes\n",
    "            predictions = []\n",
    "            num_rows, _ = X.shape\n",
    "            for idx in range(num_rows):\n",
    "                prediction = self._traverse_tree(X.iloc[idx], self.tree)\n",
    "                predictions.append(prediction)\n",
    "        return predictions\n",
    "\n",
    "    # Build tree by recursively splitting input data on best feature given information gain criterion\n",
    "    def _build_tree(self, X, Y, depth=0):\n",
    "        # Initialize variables\n",
    "        num_samples, num_features = X.shape\n",
    "        num_classes = len(set(Y))\n",
    "        best_gain = -1\n",
    "        best_split_feature = None\n",
    "        best_split_val = None\n",
    "        best_left_X= None\n",
    "        best_right_X = None\n",
    "        best_left_Y = None\n",
    "        best_right_Y = None\n",
    "        \n",
    "        # If maximum depth has been reached or all samples belong to the same class, return a leaf node\n",
    "        if depth == self.max_depth or num_classes == 1:\n",
    "            return Leaf(Y)\n",
    "        \n",
    "        for feature_idx in range(num_features): \n",
    "            # Check if X is csr_matrix\n",
    "            if(isinstance(X, scipy.sparse._csr.csr_matrix)):\n",
    "                feature_vals = X.getcol(feature_idx).toarray().transpose()[0]\n",
    "            else:\n",
    "                feature_vals = X.iloc[:, feature_idx]\n",
    "    \n",
    "            possible_vals = np.unique(feature_vals)\n",
    "            \n",
    "            for split_val in possible_vals:\n",
    "                # Calculate index values\n",
    "                left_idx = feature_vals <= split_val\n",
    "                right_idx = feature_vals > split_val\n",
    "    \n",
    "                # If either the left or right split is empty, skip this split\n",
    "                if np.sum(left_idx) == 0 or np.sum(right_idx) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if(isinstance(X, scipy.sparse._csr.csr_matrix)):\n",
    "                    # Calculate left and right \n",
    "                    left_X = X[left_idx, :]\n",
    "                    right_X = X[right_idx, :]\n",
    "                    left_Y = Y[left_idx]\n",
    "                    right_Y = Y[right_idx]\n",
    "                else:\n",
    "                    # Calculate left and right \n",
    "                    left_X = X.loc[left_idx, :]\n",
    "                    right_X = X.loc[right_idx, :]\n",
    "                    left_Y = Y.loc[left_idx]\n",
    "                    right_Y = Y.loc[right_idx]\n",
    "                \n",
    "                # Calcuate gain using information gain helper function\n",
    "                gain = self._information_gain(Y, left_Y, right_Y)\n",
    "                \n",
    "                # If gain is greater than best_gain, update \n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_split_feature = feature_idx\n",
    "                    best_split_val = split_val\n",
    "                    best_left_X = left_X\n",
    "                    best_right_X = right_X\n",
    "                    best_left_Y = left_Y\n",
    "                    best_right_Y = right_Y\n",
    "                    \n",
    "        # If best_gain is zero, return a leaf\n",
    "        if best_gain == 0:\n",
    "            return Leaf(Y)\n",
    "        \n",
    "        # Add by 0.5 to mimmic sklearn library\n",
    "        best_split_val = best_split_val + 0.5\n",
    "        \n",
    "        # If best gain > zero, build left and right tree and return node with new best_split_feature\n",
    "        left_tree = self._build_tree(best_left_X, best_left_Y, depth+1)\n",
    "        right_tree = self._build_tree(best_right_X, best_right_Y, depth+1)\n",
    "        return Node(best_split_feature, best_split_val, left_tree, right_tree)\n",
    "\n",
    "    # Traverse the decision tree to predict the class of a test sample\n",
    "    def _traverse_tree(self, x, node):\n",
    "        # If node is a leaf, return the predicted class\n",
    "        if isinstance(node, Leaf):\n",
    "            return node.predicted_class\n",
    "        \n",
    "        # Check against split_val, traverse left or right tree accordingly\n",
    "        if x[node.split_feature] < node.split_val:\n",
    "            return self._traverse_tree(x, node.left_tree)\n",
    "        else:\n",
    "            return self._traverse_tree(x, node.right_tree)\n",
    "\n",
    "    def _information_gain(self, Y, left_Y, right_Y):\n",
    "        # Initialize variables\n",
    "        num_samples = len(Y)\n",
    "        num_left = len(left_Y)\n",
    "        num_right = len(right_Y)\n",
    "        \n",
    "        # Calculate entropy before split\n",
    "        entropy_before_split = self._entropy(Y)\n",
    "        \n",
    "        # Calculate entropy after split\n",
    "        entropy_after_split = ((num_left / num_samples) * self._entropy(left_Y)\n",
    "                               + (num_right / num_samples) * self._entropy(right_Y))\n",
    "        \n",
    "        # Calculate information gain\n",
    "        return entropy_before_split - entropy_after_split\n",
    "\n",
    "    def _entropy(self, Y):\n",
    "        # Calculate the entropy of a set of samples\n",
    "        num_samples = len(Y)\n",
    "        \n",
    "        # If number of samples is zero, return zero\n",
    "        if num_samples == 0:\n",
    "            return 0\n",
    "        \n",
    "        _, counts = np.unique(Y, return_counts=True)\n",
    "        class_probs = counts / num_samples\n",
    "        \n",
    "        # Return calculated entropy\n",
    "        return -np.sum(class_probs * np.log2(class_probs))\n",
    "    \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        # Added print_tree function for debugging purposes\n",
    "        ''' function to print the tree '''\n",
    "        \n",
    "        if not tree:\n",
    "            tree = self.tree\n",
    "            \n",
    "        if(isinstance(tree, Leaf)):\n",
    "            print(tree.predicted_class)\n",
    "\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.split_feature), \"<=\", tree.split_val, \"?\")\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left_tree, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right_tree, indent + indent)\n",
    "\n",
    "\n",
    "# Node class definition\n",
    "class Node:\n",
    "    def __init__(self, split_feature, split_val, left_tree, right_tree):\n",
    "        self.split_feature = split_feature\n",
    "        self.split_val = split_val\n",
    "        self.left_tree = left_tree\n",
    "        self.right_tree = right_tree\n",
    "\n",
    "# Leaf class definition\n",
    "class Leaf:\n",
    "    def __init__(self, y):\n",
    "        self.predicted_class = Counter(y).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f4395ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into Pandas Series for X and Y, reduce dataset for model testing\n",
    "rows_to_drop = train.sample(38898).index\n",
    "reduced_data = train.drop(rows_to_drop)\n",
    "\n",
    "# Split data into Pandas Series for X and Y, reduce dataset for model testing\n",
    "X_train_t, X_val_t, Y_train_t, Y_val_t = train_test_split(reduced_data[\"text\"], reduced_data[\"label\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ec132565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text into bag-of-words features\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_reduced_t = vectorizer.fit_transform(X_train_t)\n",
    "X_val_reduced_t = vectorizer.transform(X_val_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "286a7e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with a max_depth of 50 trees, train on reduced datasets at first for testing purposes\n",
    "dt_t = DecisionTree(max_depth=50)\n",
    "dt_t.fit(X_train_reduced_t, Y_train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d4152c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the decision tree to predict the classes of the test data\n",
    "y_pred_t = dt_t.predict(X_val_reduced_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "775449a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.985"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Score\n",
    "accuracy_score(Y_val_t, y_pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c999b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE ABOUT SCORES:\n",
    "# Model was working perfectly before but when running last time... I had made some changes before pushing to git\n",
    "# and must have changed one small thing that broke it, unforunately, the model took so long to run, I ran out of\n",
    "# time to see that errors had occured while waiting on accuracy, recall, and f1 score\n",
    "# Will attempt to resolve ahead of presentation and resubmit if allowed\n",
    "\n",
    "# UPDATE - 5/8/2023\n",
    "# Found bug, was a scoping error and the left and right X/Y were being passed incorrectly due to a \n",
    "# scoping issue when I refactored code, I deleted the initialization of varaibles, works properly now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "585ac4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ab7626f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text into bag-of-words features - FINAL\n",
    "X_train_final = vectorizer.fit_transform(X_train)\n",
    "X_val_final = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c0c2864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Y values - FINAL\n",
    "Y_train_final = pd.DataFrame(train, columns = ['label']).squeeze()\n",
    "Y_val_final = pd.DataFrame(test, columns = ['label']).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d6bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with a max_depth of 50 trees, train on reduced datasets at first for testing purposes\n",
    "dt_final = DecisionTree(max_depth=50)\n",
    "dt_final.fit(X_train_final, Y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d397c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the decision tree to predict the classes on training set - Final\n",
    "Y_pred_train_final = dt_final.predict(X_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the decision tree to predict the classes on validation set - Final\n",
    "Y_pred_final = dt_final.predict(X_val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48024f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy of the model on training set - Final\n",
    "accuracy_train = accuracy_score(Y_train_final, Y_pred_train_final)\n",
    "print('Training Accuracy:', accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afac3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy of the model on validation set - Final\n",
    "accuracy_val = accuracy_score(Y_val_final, Y_pred_final)\n",
    "print('Validation Accuracy:', accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedb40e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the F1 score of the model on training set - Final\n",
    "f1_train = f1_score(Y_train_final, Y_pred_train_final, average='binary', pos_label='real'))\n",
    "print('Training F1:', f1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f0baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the F1 score of the model on validation set - Final\n",
    "f1_val = f1_score(Y_val_final, Y_pred_final, average='binary', pos_label='real'))\n",
    "print('Val F1:', f1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the precision score of the model on training set - Final\n",
    "precision_train = f1_score(Y_train_final, Y_pred_train_final, average='binary', pos_label='real'))\n",
    "print('Precision Train:', precision_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3421519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the precision score of the model on validation set - Final\n",
    "precision_val = f1_score(Y_val_final, Y_pred_final, average='binary', pos_label='real'))\n",
    "print('Precision Val:', precision_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "18effd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTS ON IRIS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3264865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'type']\n",
    "csv_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "data = pd.read_csv(csv_url, header = None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1a96a1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "Y = data.iloc[:, -1]\n",
    "\n",
    "X_train_iris, X_test_iris, Y_train_iris, Y_test_iris = train_test_split(X, Y, test_size=.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8e5c2ea3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Idx: 2 - Gain: 0.9264046681474138\n",
      "Feature Idx: 3 - Gain: 0.7694993941591152\n",
      "Feature Idx: 2 - Gain: 0.17556502585750278\n",
      "Feature Idx: 2 - Gain: 0.1228956258058704\n",
      "Feature Idx: 1 - Gain: 0.46691718668869925\n",
      "Feature Idx: 0 - Gain: 0.2516291673878229\n",
      "Feature Idx: 0 - Gain: 1.0\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTree()\n",
    "dt.fit(X_train_iris, Y_train_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1b7c42f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_2 <= 1.9 ?\n",
      " left:Iris-setosa\n",
      " right:X_3 <= 1.5 ?\n",
      "  left:X_2 <= 4.9 ?\n",
      "    left:Iris-versicolor\n",
      "    right:Iris-virginica\n",
      "  right:X_2 <= 5.0 ?\n",
      "    left:X_1 <= 2.8 ?\n",
      "        left:Iris-virginica\n",
      "        right:X_0 <= 5.9 ?\n",
      "                left:Iris-versicolor\n",
      "                right:X_0 <= 6.0 ?\n",
      "                                left:Iris-virginica\n",
      "                                right:Iris-versicolor\n",
      "    right:Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "dt.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "280fb21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_iris = dt.predict(X_test_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fdaa5ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test_iris, Y_pred_iris)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
